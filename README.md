# Red Neuronal para Clasificaci√≥n de Frutas

Este proyecto implementa una red neuronal multicapa (MLP) para clasificar frutas como maduras o no maduras bas√°ndose en caracter√≠sticas de color y firmeza.

## Caracter√≠sticas

- **Dataset**: 1000 muestras de frutas sint√©ticas con caracter√≠sticas color, firmness y etiqueta (1=madura, 0=no madura)
- **Preprocesamiento**: Escalado de caracter√≠sticas usando StandardScaler
- **Divisi√≥n de datos**: 75% entrenamiento, 25% prueba
- **Arquitectura MLP**:
  - Capa oculta: 10 neuronas con activaci√≥n ReLU
  - Capa de salida: 1 neurona con activaci√≥n sigmoide
- **Optimizaci√≥n**: Adam optimizer con funci√≥n de p√©rdida binary_crossentropy
- **Visualizaciones**: Gr√°ficos de dispersi√≥n con frontera de decisi√≥n y distribuci√≥n de clases
- **Predicciones**: Sistema para clasificar frutas nuevas sin etiquetas

## Instalaci√≥n

1. Instalar las dependencias:

```bash
pip install -r requirements.txt
```

## Uso

Ejecutar el script principal:

```bash
python red_neuronal_frutas.py
```

## Diagramas de Flujo

### Pipeline principal

```mermaid
flowchart TD
    A[Inicio] --> B[main()]
    B --> C[Cargar y escalar datos<br/>cargar_y_preprocesar_datos()]
    C --> D[Dividir en train/test<br/>dividir_datos()]
    D --> E[Crear modelo MLP<br/>crear_modelo_mlp()]
    E --> F[Entrenar con EarlyStopping<br/>entrenar_modelo()]
    F --> G[Evaluar en test<br/>evaluar_modelo()]
    G --> H[Gr√°fico distribuci√≥n clases<br/>grafico_distribucion_clases()]
    H --> I[Dispersi√≥n + frontera (original)<br/>grafico_dispersion_frontera(X_original)]
    I --> J[Dispersi√≥n + frontera (escalado)<br/>grafico_dispersion_frontera(X_escalado)]
    J --> K[Historial de entrenamiento<br/>grafico_historial_entrenamiento()]
    K --> L{¬øfrutas_nuevas.csv existe?}
    L -- S√≠ --> M[procesar_frutas_nuevas()<br/>transform + predict]
    L -- No --> N[Omitir predicci√≥n nuevas]
    M --> O[Gr√°fico frutas nuevas<br/>grafico_frutas_nuevas()]
    N --> P{¬øfrutas_validacion.csv existe?}
    O --> P
    P -- S√≠ --> Q[validar_predicciones_frutas_nuevas()<br/>transform + predict + m√©tricas]
    P -- No --> R[Omitir validaci√≥n]
    Q --> S[Gr√°fico validaci√≥n + frontera<br/>grafico_validacion_con_frontera()]
    R --> T[Analizar casos extremos<br/>analizar_casos_extremos()]
    S --> T
    T --> U[Imprimir Accuracy final]
    U --> V[Fin]
```

### Predicci√≥n en nuevas frutas y validaci√≥n

```mermaid
flowchart TD
    A[Iniciar m√≥dulo de nuevas/validaci√≥n] --> B{Existe frutas_nuevas.csv?}
    B -- S√≠ --> C[Cargar X_nuevas]
    C --> D[scaler.transform(X_nuevas)]
    D --> E[model.predict ‚Üí proba y etiqueta (>0.5)]
    E --> F[Agregar columnas prediccion y probabilidad]
    F --> G[Graficar frutas nuevas]
    B -- No --> H[Informar ausencia y continuar]

    G --> I{Existe frutas_validacion.csv?}
    H --> I
    I -- S√≠ --> J[Cargar X_val, y_real]
    J --> K[scaler.transform(X_val)]
    K --> L[model.predict ‚Üí predicciones]
    L --> M[Calcular accuracy y matriz de confusi√≥n]
    M --> N[Armar df_comparacion (+ confianza)]
    N --> O[Graficar validaci√≥n + frontera]
    I -- No --> P[Informar ausencia y continuar]

    O --> Q[Analizar casos extremos<br/>puntos sint√©ticos]
    P --> Q
    Q --> R[Fin m√≥dulo]
```

## Salidas

El programa genera:

1. **M√©tricas de evaluaci√≥n**: Accuracy y matriz de confusi√≥n
2. **Gr√°fico de barras**: Distribuci√≥n de frutas maduras vs no maduras
3. **Gr√°fico de dispersi√≥n**: Datos con frontera de decisi√≥n (datos originales)
4. **Gr√°fico de dispersi√≥n**: Datos con frontera de decisi√≥n (datos escalados)
5. **Historial de entrenamiento**: Curvas de accuracy y p√©rdida
6. **Predicciones de frutas nuevas**: Clasificaci√≥n de datos sin etiquetas
7. **Gr√°fico de predicciones**: Visualizaci√≥n de frutas nuevas clasificadas

## Archivos

- `red_neuronal_frutas.py`: Script principal con toda la implementaci√≥n
- `frutas_sinteticas_1000.csv`: Dataset de frutas con 1000 muestras para entrenamiento
- `frutas_nuevas.csv`: Dataset de frutas nuevas para predicci√≥n (sin etiquetas)
- `frutas_validacion.csv`: Dataset de validaci√≥n con etiquetas reales para verificar predicciones
- `requirements.txt`: Dependencias del proyecto
- `README.md`: Este archivo de documentaci√≥n

---

## Documentaci√≥n Completa de Funciones

### Importaciones y Configuraci√≥n Inicial

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n para gr√°ficos en espa√±ol
plt.rcParams['font.size'] = 12
plt.rcParams['figure.figsize'] = (10, 6)
```

**Prop√≥sito**: Importa todas las librer√≠as necesarias para el proyecto:

- **pandas**: Manipulaci√≥n de datos CSV
- **numpy**: Operaciones matem√°ticas y arrays
- **matplotlib/seaborn**: Creaci√≥n de gr√°ficos
- **sklearn**: Herramientas de machine learning (divisi√≥n de datos, escalado, m√©tricas)
- **tensorflow/keras**: Construcci√≥n y entrenamiento de redes neuronales
- **warnings**: Suprime mensajes de advertencia para una salida m√°s limpia

---

## 1. Funci√≥n `cargar_y_preprocesar_datos()`

```python
def cargar_y_preprocesar_datos():
    """Carga y preprocesa el dataset de frutas"""
    print("Cargando dataset de frutas...")

    # Cargar datos
    data = pd.read_csv('frutas_sinteticas_1000.csv')
    print(f"Dataset cargado: {data.shape[0]} muestras, {data.shape[1]} caracter√≠sticas")

    # Separar caracter√≠sticas y etiquetas
    X = data[['color', 'firmness']].values
    y = data['label'].values

    # Escalar caracter√≠sticas
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    return X_scaled, y, scaler, data
```

**¬øPara qu√© sirve?**

- Carga el dataset CSV con 1000 muestras de frutas
- Separa las caracter√≠sticas (color, firmness) de las etiquetas (label)
- Normaliza los datos usando StandardScaler para que tengan media 0 y desviaci√≥n est√°ndar 1

**¬øC√≥mo funciona?**

1. Lee el archivo CSV usando pandas
2. Extrae las columnas 'color' y 'firmness' como caracter√≠sticas (X)
3. Extrae la columna 'label' como etiquetas (y)
4. Crea un StandardScaler y ajusta los datos para normalizarlos
5. Retorna los datos escalados, etiquetas, el scaler y los datos originales

**¬øPor qu√© es importante el escalado?**

- Las redes neuronales funcionan mejor cuando los datos est√°n en rangos similares
- Evita que una caracter√≠stica domine sobre otra por tener valores m√°s grandes

---

## 2. Funci√≥n `dividir_datos(X, y)`

```python
def dividir_datos(X, y):
    """Divide los datos en entrenamiento (75%) y prueba (25%)"""
    print("Dividiendo datos en entrenamiento (75%) y prueba (25%)...")

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=42, stratify=y
    )

    print(f"Conjunto de entrenamiento: {X_train.shape[0]} muestras")
    print(f"Conjunto de prueba: {X_test.shape[0]} muestras")

    return X_train, X_test, y_train, y_test
```

**¬øPara qu√© sirve?**

- Divide los datos en dos conjuntos: entrenamiento (75%) y prueba (25%)
- Garantiza que la proporci√≥n de clases se mantenga en ambos conjuntos

**¬øC√≥mo funciona?**

1. Usa `train_test_split` de sklearn para dividir aleatoriamente
2. `test_size=0.25`: 25% para prueba, 75% para entrenamiento
3. `random_state=42`: Fija la semilla aleatoria para resultados reproducibles
4. `stratify=y`: Mantiene la proporci√≥n de clases (maduras/no maduras) en ambos conjuntos

**¬øPor qu√© dividir los datos?**

- **Entrenamiento**: Para que el modelo aprenda los patrones
- **Prueba**: Para evaluar qu√© tan bien generaliza el modelo a datos nuevos
- **Estratificaci√≥n**: Evita sesgos en la evaluaci√≥n

---

## 3. Funci√≥n `crear_modelo_mlp()`

```python
def crear_modelo_mlp():
    """Crea la red neuronal multicapa"""
    print("Creando red neuronal multicapa...")

    model = keras.Sequential([
        layers.Dense(10, activation='relu', input_shape=(2,), name='capa_oculta'),
        layers.Dense(1, activation='sigmoid', name='capa_salida')
    ])

    # Compilar modelo
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    print("Arquitectura del modelo:")
    model.summary()

    return model
```

**¬øPara qu√© sirve?**

- Construye la arquitectura de la red neuronal multicapa (MLP)
- Configura el optimizador, funci√≥n de p√©rdida y m√©tricas

**¬øC√≥mo funciona?**

1. **Capa oculta**: 10 neuronas con activaci√≥n ReLU
   - ReLU: f(x) = max(0, x) - solo activa neuronas con valores positivos
   - Input shape: (2,) porque tenemos 2 caracter√≠sticas (color, firmness)
2. **Capa de salida**: 1 neurona con activaci√≥n sigmoide
   - Sigmoide: f(x) = 1/(1 + e^(-x)) - produce probabilidades entre 0 y 1
3. **Compilaci√≥n**:
   - **Optimizador Adam**: Algoritmo de optimizaci√≥n adaptativo
   - **Binary crossentropy**: Funci√≥n de p√©rdida para clasificaci√≥n binaria
   - **Accuracy**: M√©trica para evaluar el rendimiento

**¬øPor qu√© esta arquitectura?**

- **ReLU**: Evita el problema de desvanecimiento del gradiente
- **Sigmoide**: Perfecta para clasificaci√≥n binaria (madura/no madura)
- **Adam**: Optimizador robusto que se adapta a diferentes tipos de datos

---

## 4. Funci√≥n `entrenar_modelo(model, X_train, y_train, X_test, y_test)`

```python
def entrenar_modelo(model, X_train, y_train, X_test, y_test):
    """Entrena el modelo y muestra el progreso"""
    print("Entrenando modelo...")

    # Configurar callback para early stopping
    early_stopping = keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=20,
        restore_best_weights=True
    )

    # Entrenar modelo
    history = model.fit(
        X_train, y_train,
        epochs=100,
        batch_size=8,
        validation_data=(X_test, y_test),
        callbacks=[early_stopping],
        verbose=1
    )

    return history
```

**¬øPara qu√© sirve?**

- Entrena la red neuronal usando los datos de entrenamiento
- Implementa early stopping para evitar sobreajuste
- Monitorea el progreso con datos de validaci√≥n

**¬øC√≥mo funciona?**

1. **Early Stopping**:
   - Monitorea `val_loss` (p√©rdida en validaci√≥n)
   - Si no mejora por 20 √©pocas, detiene el entrenamiento
   - Restaura los mejores pesos encontrados
2. **Entrenamiento**:
   - `epochs=100`: M√°ximo 100 iteraciones completas
   - `batch_size=8`: Procesa 8 muestras a la vez
   - `validation_data`: Usa datos de prueba para validaci√≥n
   - `verbose=1`: Muestra el progreso

**¬øPor qu√© early stopping?**

- Evita el sobreajuste (memorizar datos de entrenamiento)
- Encuentra el punto √≥ptimo de entrenamiento
- Mejora la generalizaci√≥n del modelo

---

## 5. Funci√≥n `evaluar_modelo(model, X_test, y_test)`

```python
def evaluar_modelo(model, X_test, y_test):
    """Eval√∫a el modelo y muestra m√©tricas"""
    print("\nEvaluando modelo...")

    # Predicciones
    y_pred_proba = model.predict(X_test)
    y_pred = (y_pred_proba > 0.5).astype(int).flatten()

    # M√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {accuracy:.4f}")

    # Matriz de confusi√≥n
    cm = confusion_matrix(y_test, y_pred)
    print("\nMatriz de confusi√≥n:")
    print(cm)

    # Reporte de clasificaci√≥n
    print("\nReporte de clasificaci√≥n:")
    print(classification_report(y_test, y_pred, target_names=['No Madura', 'Madura']))

    return y_pred, accuracy, cm
```

**¬øPara qu√© sirve?**

- Eval√∫a el rendimiento del modelo entrenado
- Calcula m√©tricas de clasificaci√≥n
- Genera reportes detallados

**¬øC√≥mo funciona?**

1. **Predicciones**:
   - Obtiene probabilidades del modelo
   - Convierte a clases usando umbral 0.5 (>0.5 = madura)
2. **Accuracy**: Porcentaje de predicciones correctas
3. **Matriz de confusi√≥n**:
   - Verdadero Negativo | Falso Positivo
   - Falso Negativo | Verdadero Positivo
4. **Reporte de clasificaci√≥n**: Precision, Recall, F1-score para cada clase

**¬øQu√© significan las m√©tricas?**

- **Accuracy**: Precisi√≥n general del modelo
- **Precision**: De las frutas predichas como maduras, ¬øcu√°ntas lo son realmente?
- **Recall**: De las frutas realmente maduras, ¬øcu√°ntas detect√≥ el modelo?
- **F1-score**: Media arm√≥nica entre precision y recall

---

## 6. Funci√≥n `grafico_dispersion_frontera(X, y, model, scaler, titulo)`

```python
def grafico_dispersion_frontera(X, y, model, scaler, titulo="Datos de Frutas con Frontera de Decisi√≥n"):
    """Crea gr√°fico de dispersi√≥n con frontera de decisi√≥n"""
    plt.figure(figsize=(12, 8))

    # Crear malla para frontera de decisi√≥n
    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                         np.linspace(y_min, y_max, 100))

    # Predecir en la malla
    mesh_points = np.c_[xx.ravel(), yy.ravel()]
    mesh_points_scaled = scaler.transform(mesh_points)
    Z = model.predict(mesh_points_scaled)
    Z = Z.reshape(xx.shape)

    # Gr√°fico de contorno para frontera de decisi√≥n
    plt.contourf(xx, yy, Z, levels=50, alpha=0.6, cmap='RdYlBu')
    plt.colorbar(label='Probabilidad de Madurez')

    # Puntos de datos
    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu',
                         edgecolors='black', s=50, alpha=0.8)

    plt.xlabel('Color (escalado)')
    plt.ylabel('Firmeza (escalado)')
    plt.title(titulo)
    plt.legend(handles=scatter.legend_elements()[0],
              labels=['No Madura', 'Madura'], loc='upper right')

    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
```

**¬øPara qu√© sirve?**

- Visualiza los datos de frutas en un diagrama de dispersi√≥n
- Muestra la frontera de decisi√≥n aprendida por la red neuronal
- Permite ver c√≥mo el modelo clasifica diferentes regiones del espacio de caracter√≠sticas

**¬øC√≥mo funciona?**

1. **Crear malla**: Genera una cuadr√≠cula de puntos en el espacio de caracter√≠sticas
2. **Predicciones**: Para cada punto de la malla, predice la probabilidad de madurez
3. **Contorno de decisi√≥n**: Dibuja regiones coloreadas seg√∫n la probabilidad
4. **Puntos de datos**: Superpone los datos reales con colores seg√∫n su clase real
5. **Leyenda**: Indica qu√© colores representan cada clase

**¬øQu√© nos dice la frontera de decisi√≥n?**

- **Regiones rojas**: Alta probabilidad de frutas no maduras
- **Regiones azules**: Alta probabilidad de frutas maduras
- **Transici√≥n**: √Årea donde el modelo tiene incertidumbre
- **Separaci√≥n**: Qu√© tan bien separa el modelo las dos clases

---

## 7. Funci√≥n `grafico_distribucion_clases(data)`

```python
def grafico_distribucion_clases(data):
    """Crea gr√°fico de barras de distribuci√≥n de clases"""
    plt.figure(figsize=(8, 6))

    # Contar clases
    conteo = data['label'].value_counts()
    etiquetas = ['No Madura', 'Madura']

    # Gr√°fico de barras
    barras = plt.bar(etiquetas, conteo.values, color=['#ff7f7f', '#7fbf7f'],
                    edgecolor='black', alpha=0.7)

    # Agregar valores en las barras
    for barra in barras:
        altura = barra.get_height()
        plt.text(barra.get_x() + barra.get_width()/2., altura + 0.5,
                f'{int(altura)}', ha='center', va='bottom', fontweight='bold')

    plt.ylabel('Cantidad de Frutas')
    plt.title('Distribuci√≥n de Frutas Maduras y No Maduras')
    plt.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.show()
```

**¬øPara qu√© sirve?**

- Muestra la distribuci√≥n de clases en el dataset
- Permite verificar si hay balance entre clases
- Facilita la interpretaci√≥n del dataset

**¬øC√≥mo funciona?**

1. Cuenta cu√°ntas frutas hay de cada clase
2. Crea barras con colores diferentes para cada clase
3. Agrega valores num√©ricos encima de cada barra
4. Aplica formato con leyendas y grid

**¬øPor qu√© es importante?**

- **Balance de clases**: Si hay muchas m√°s frutas de una clase, el modelo puede sesgarse
- **Interpretaci√≥n**: Ayuda a entender la naturaleza del problema
- **Validaci√≥n**: Confirma que los datos est√°n bien cargados

---

## 8. Funci√≥n `grafico_historial_entrenamiento(history)`

```python
def grafico_historial_entrenamiento(history):
    """Muestra el historial de entrenamiento"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    # Accuracy
    ax1.plot(history.history['accuracy'], label='Entrenamiento')
    ax1.plot(history.history['val_accuracy'], label='Validaci√≥n')
    ax1.set_title('Accuracy del Modelo')
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('Accuracy')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Loss
    ax2.plot(history.history['loss'], label='Entrenamiento')
    ax2.plot(history.history['val_loss'], label='Validaci√≥n')
    ax2.set_title('P√©rdida del Modelo')
    ax2.set_xlabel('√âpoca')
    ax2.set_ylabel('P√©rdida')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()
```

**¬øPara qu√© sirve?**

- Visualiza c√≥mo evolucion√≥ el entrenamiento
- Permite detectar problemas como sobreajuste o subajuste
- Ayuda a entender el comportamiento del modelo

**¬øC√≥mo funciona?**

1. **Accuracy**: Muestra la precisi√≥n en entrenamiento vs validaci√≥n
2. **Loss**: Muestra la p√©rdida en entrenamiento vs validaci√≥n
3. **Dos gr√°ficos**: Uno para cada m√©trica

**¬øQu√© patrones buscar?**

- **Sobreajuste**: Accuracy de entrenamiento sube, pero la de validaci√≥n baja
- **Subajuste**: Ambas curvas se mantienen bajas
- **Buen entrenamiento**: Ambas curvas suben juntas
- **Early stopping efectivo**: El entrenamiento se detiene cuando la validaci√≥n deja de mejorar

---

## 9. Funci√≥n `main()`

```python
def main():
    """Funci√≥n principal que ejecuta todo el pipeline"""
    print("="*60)
    print("RED NEURONAL PARA CLASIFICACI√ìN DE FRUTAS MADURAS")
    print("="*60)

    # 1. Cargar y preprocesar datos
    X, y, scaler, data = cargar_y_preprocesar_datos()

    # 2. Dividir datos
    X_train, X_test, y_train, y_test = dividir_datos(X, y)

    # 3. Crear modelo
    model = crear_modelo_mlp()

    # 4. Entrenar modelo
    history = entrenar_modelo(model, X_train, y_train, X_test, y_test)

    # 5. Evaluar modelo
    y_pred, accuracy, cm = evaluar_modelo(model, X_test, y_test)

    # 6. Gr√°ficos
    print("\nGenerando gr√°ficos...")

    # Gr√°fico de distribuci√≥n de clases
    grafico_distribucion_clases(data)

    # Gr√°fico de dispersi√≥n con frontera de decisi√≥n (datos originales)
    X_original = data[['color', 'firmness']].values
    grafico_dispersion_frontera(X_original, y, model, scaler,
                               "Frontera de Decisi√≥n - Datos Originales")

    # Gr√°fico de dispersi√≥n con frontera de decisi√≥n (datos escalados)
    grafico_dispersion_frontera(X, y, model, StandardScaler().fit(X),
                               "Frontera de Decisi√≥n - Datos Escalados")

    # Historial de entrenamiento
    grafico_historial_entrenamiento(history)

    print("\n" + "="*60)
    print("AN√ÅLISIS COMPLETADO")
    print(f"Accuracy final: {accuracy:.4f}")
    print("="*60)
```

**¬øPara qu√© sirve?**

- Orquesta todo el pipeline de machine learning
- Ejecuta las funciones en el orden correcto
- Genera todos los an√°lisis y visualizaciones

**¬øC√≥mo funciona?**

1. **Paso 1**: Carga y preprocesa los datos
2. **Paso 2**: Divide en conjuntos de entrenamiento y prueba
3. **Paso 3**: Crea la arquitectura de la red neuronal
4. **Paso 4**: Entrena el modelo
5. **Paso 5**: Eval√∫a el rendimiento
6. **Paso 6**: Genera visualizaciones

**¬øPor qu√© esta estructura?**

- **Modular**: Cada funci√≥n tiene una responsabilidad espec√≠fica
- **Reutilizable**: Las funciones se pueden usar independientemente
- **Mantenible**: F√°cil de modificar y depurar
- **Legible**: El flujo es claro y f√°cil de seguir

---

### 10. Funci√≥n `procesar_frutas_nuevas(model, scaler)`

```python
def procesar_frutas_nuevas(model, scaler):
    """Carga, procesa y hace predicciones sobre frutas nuevas sin etiquetas"""
    print("\n" + "="*50)
    print("PROCESANDO FRUTAS NUEVAS")
    print("="*50)

    try:
        # Cargar frutas nuevas
        print("Cargando frutas nuevas...")
        frutas_nuevas = pd.read_csv('frutas_nuevas.csv')
        print(f"Frutas nuevas cargadas: {frutas_nuevas.shape[0]} muestras")

        # Verificar columnas
        if not all(col in frutas_nuevas.columns for col in ['color', 'firmness']):
            print("‚ùå Error: El archivo debe contener columnas 'color' y 'firmness'")
            return None

        # Extraer caracter√≠sticas
        X_nuevas = frutas_nuevas[['color', 'firmness']].values
        print(f"Caracter√≠sticas extra√≠das: {X_nuevas.shape}")

        # Escalar usando el mismo scaler entrenado
        print("Escalando caracter√≠sticas con el scaler entrenado...")
        X_nuevas_scaled = scaler.transform(X_nuevas)

        # Hacer predicciones
        print("Realizando predicciones...")
        predicciones_proba = model.predict(X_nuevas_scaled, verbose=0)
        predicciones = (predicciones_proba > 0.5).astype(int).flatten()

        # Agregar predicciones al DataFrame
        frutas_nuevas['prediccion'] = predicciones
        frutas_nuevas['probabilidad'] = predicciones_proba.flatten()

        # Mostrar resultados
        print("\nPrimeras 10 frutas nuevas con predicciones:")
        print(frutas_nuevas.head(10))

        # Estad√≠sticas de predicciones
        conteo_predicciones = frutas_nuevas['prediccion'].value_counts()
        print(f"\nResumen de predicciones:")
        print(f"Frutas predichas como No Maduras (0): {conteo_predicciones.get(0, 0)}")
        print(f"Frutas predichas como Maduras (1): {conteo_predicciones.get(1, 0)}")

        return frutas_nuevas, X_nuevas, predicciones

    except FileNotFoundError:
        print("‚ùå Error: No se encontr√≥ el archivo 'frutas_nuevas.csv'")
        print("üí° Creando archivo de ejemplo...")
        return None
    except Exception as e:
        print(f"‚ùå Error al procesar frutas nuevas: {e}")
        return None
```

**¬øPara qu√© sirve?**

- Carga frutas nuevas sin etiquetas de madurez
- Aplica el mismo preprocesamiento usado en entrenamiento
- Hace predicciones usando el modelo ya entrenado
- Genera estad√≠sticas de las predicciones

**¬øC√≥mo funciona?**

1. **Carga de datos**: Lee el archivo `frutas_nuevas.csv` con columnas 'color' y 'firmness'
2. **Verificaci√≥n**: Confirma que las columnas necesarias est√©n presentes
3. **Preprocesamiento**: Usa el mismo StandardScaler entrenado para escalar las caracter√≠sticas
4. **Predicciones**: Aplica el modelo entrenado para obtener probabilidades y clases
5. **Resultados**: Agrega predicciones y probabilidades al DataFrame original
6. **Estad√≠sticas**: Muestra resumen de las predicciones realizadas

**¬øPor qu√© es importante usar el mismo scaler?**

- **Consistencia**: Mantiene la misma escala que se us√≥ en entrenamiento
- **Precisi√≥n**: Evita errores de predicci√≥n por diferencias de escala
- **Generalizaci√≥n**: Asegura que el modelo funcione correctamente con datos nuevos

---

### 11. Funci√≥n `grafico_frutas_nuevas(frutas_nuevas, X_nuevas, predicciones)`

```python
def grafico_frutas_nuevas(frutas_nuevas, X_nuevas, predicciones):
    """Genera gr√°fico de dispersi√≥n de frutas nuevas con predicciones"""
    plt.figure(figsize=(12, 8))

    # Definir colores para las predicciones
    colores = ['#ff4444', '#44ff44']  # Rojo para No Madura, Verde para Madura
    etiquetas = ['No Madura', 'Madura']

    # Crear el gr√°fico de dispersi√≥n
    scatter = plt.scatter(X_nuevas[:, 0], X_nuevas[:, 1],
                         c=predicciones,
                         cmap='RdYlGn',
                         edgecolors='black',
                         s=100,
                         alpha=0.8)

    plt.xlabel('Color')
    plt.ylabel('Firmeza')
    plt.title('Predicciones de Madurez - Frutas Nuevas')

    # Crear leyenda personalizada
    handles = [plt.scatter([], [], c=colores[i], s=100, edgecolors='black',
                          alpha=0.8, label=etiquetas[i])
               for i in range(len(etiquetas))]
    plt.legend(handles=handles, title='Predicci√≥n', loc='upper right')

    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    print("‚úÖ Gr√°fico de frutas nuevas generado")
```

**¬øPara qu√© sirve?**

- Visualiza las frutas nuevas en un diagrama de dispersi√≥n
- Muestra las predicciones usando colores (rojo=no madura, verde=madura)
- Permite interpretar visualmente los resultados del modelo

**¬øC√≥mo funciona?**

1. **Configuraci√≥n**: Define colores espec√≠ficos para cada clase predicha
2. **Gr√°fico**: Crea un scatter plot con colores seg√∫n las predicciones
3. **Leyenda**: Incluye una leyenda clara con los colores y sus significados
4. **Formato**: Aplica grid, etiquetas y t√≠tulo para mejor legibilidad

**¬øPor qu√© esta visualizaci√≥n?**

- **Interpretaci√≥n**: Facilita entender las predicciones del modelo
- **Validaci√≥n**: Permite detectar patrones o anomal√≠as en las predicciones
- **Comunicaci√≥n**: Hace m√°s f√°cil explicar los resultados a otros

---

## Nuevas Funcionalidades: Predicci√≥n de Frutas Nuevas

### ¬øPor qu√© se implement√≥ esta funcionalidad?

**1. Aplicaci√≥n Pr√°ctica del Modelo:**

- **Prop√≥sito**: Demostrar c√≥mo usar un modelo entrenado en datos reales
- **Utilidad**: Clasificar frutas nuevas sin necesidad de etiquetas manuales
- **Escalabilidad**: Procesar m√∫ltiples muestras de forma autom√°tica

**2. Validaci√≥n del Sistema:**

- **Consistencia**: Verificar que el modelo funciona con datos no vistos
- **Robustez**: Probar la generalizaci√≥n del modelo entrenado
- **Calidad**: Evaluar si las predicciones son razonables

**3. Casos de Uso Reales:**

- **Industria alimentaria**: Clasificaci√≥n autom√°tica de frutas en producci√≥n
- **Control de calidad**: Detecci√≥n de madurez en tiempo real
- **Investigaci√≥n**: An√°lisis de nuevas variedades de frutas

### ¬øC√≥mo funciona el flujo de predicci√≥n?

**Paso 1: Carga de Datos Nuevos**

```
frutas_nuevas.csv ‚Üí DataFrame con columnas [color, firmness]
```

**Paso 2: Preprocesamiento Consistente**

```
Datos originales ‚Üí StandardScaler entrenado ‚Üí Datos escalados
```

**Paso 3: Predicci√≥n**

```
Datos escalados ‚Üí Modelo entrenado ‚Üí Probabilidades ‚Üí Clases (0/1)
```

**Paso 4: Visualizaci√≥n**

```
Datos + Predicciones ‚Üí Gr√°fico de dispersi√≥n colorizado
```

### Estructura del Archivo `frutas_nuevas.csv`

El archivo debe contener exactamente estas columnas:

```csv
color,firmness
2.1,3.2
4.5,4.8
1.8,2.5
...
```

**Requisitos:**

- **Columnas**: `color` y `firmness` (exactamente estos nombres)
- **Sin columna `label`**: Las etiquetas se generan autom√°ticamente
- **Formato num√©rico**: Valores decimales para las caracter√≠sticas
- **Sin encabezados adicionales**: Solo las columnas mencionadas

### Interpretaci√≥n de Resultados

**Predicciones:**

- **0 (No Madura)**: Fruta predicha como no madura (color rojo en gr√°fico)
- **1 (Madura)**: Fruta predicha como madura (color verde en gr√°fico)

**Probabilidades:**

- **Valor cercano a 0**: Alta confianza en "No Madura"
- **Valor cercano a 1**: Alta confianza en "Madura"
- **Valor cercano a 0.5**: Incertidumbre del modelo

**Estad√≠sticas mostradas:**

- Conteo de frutas predichas como maduras vs no maduras
- Distribuci√≥n de predicciones en el dataset
- Primera vista de datos con predicciones

### Ventajas de esta Implementaci√≥n

**1. Reutilizaci√≥n del Modelo:**

- No requiere reentrenar el modelo
- Mantiene la consistencia del preprocesamiento
- Aprovecha el conocimiento ya aprendido

**2. Escalabilidad:**

- Procesa cualquier cantidad de frutas nuevas
- Automatiza la clasificaci√≥n
- Reduce el trabajo manual

**3. Interpretabilidad:**

- Visualizaci√≥n clara de resultados
- Estad√≠sticas descriptivas
- Probabilidades de confianza

**4. Robustez:**

- Manejo de errores (archivo no encontrado, columnas faltantes)
- Validaci√≥n de datos de entrada
- Mensajes informativos para el usuario

---

## ¬øC√≥mo Saber si las Predicciones de Frutas Nuevas son Correctas?

### Problema Fundamental

**La pregunta clave**: Cuando el modelo predice la madurez de frutas nuevas, ¬øc√≥mo sabemos si est√° bien?

**La respuesta**: No podemos saberlo con certeza absoluta sin etiquetas reales, pero podemos usar varias estrategias para evaluar la confiabilidad.

### Estrategias de Validaci√≥n Implementadas

#### 1. **Validaci√≥n con Dataset de Prueba**

**Funci√≥n**: `validar_predicciones_frutas_nuevas()`

**¬øC√≥mo funciona?**

- Usa el archivo `frutas_validacion.csv` con etiquetas reales
- Aplica el mismo modelo a datos con etiquetas conocidas
- Compara predicciones vs etiquetas reales
- Calcula accuracy, matriz de confusi√≥n y an√°lisis detallado

**¬øQu√© nos dice?**

- **Accuracy alto (>0.8)**: El modelo es confiable
- **Accuracy bajo (<0.6)**: El modelo tiene problemas
- **Casos de error**: Qu√© tipos de frutas se clasifican mal

```python
# Ejemplo de salida:
üìä RESULTADOS DE VALIDACI√ìN:
Accuracy en frutas nuevas: 0.9000
Matriz de confusi√≥n:
[[8 1]
 [1 9]]

‚úÖ PERFECTO: 18/20 predicciones correctas!
```

#### 2. **An√°lisis de Casos Extremos**

**Funci√≥n**: `analizar_casos_extremos()`

**¬øC√≥mo funciona?**

- Prueba casos con valores conocidos
- Valida comportamiento en casos obvios
- Detecta inconsistencias l√≥gicas

**Casos de prueba:**

- `[1.0, 1.0]`: Claramente no madura
- `[8.0, 8.0]`: Claramente madura
- `[7.0, 2.0]`: Caso contradictorio (color alto, firmeza baja)
- `[2.0, 7.0]`: Caso contradictorio (color bajo, firmeza alta)

**¬øQu√© nos dice?**

- **Casos obvios correctos**: El modelo entiende patrones b√°sicos
- **Casos contradictorios**: C√≥mo maneja situaciones ambiguas

#### 3. **An√°lisis de Confianza**

**¬øC√≥mo funciona?**

- Examina las probabilidades de predicci√≥n
- Identifica casos con baja confianza (0.3 < prob < 0.7)
- Se√±ala predicciones inciertas

**¬øQu√© nos dice?**

- **Alta confianza**: Predicciones m√°s confiables
- **Baja confianza**: Casos que requieren revisi√≥n manual
- **Patrones de incertidumbre**: √Åreas donde el modelo duda

#### 4. **Visualizaci√≥n de Frontera de Decisi√≥n**

**Funci√≥n**: `grafico_validacion_con_frontera()`

**¬øC√≥mo funciona?**

- Muestra etiquetas reales vs predicciones
- Superpone la frontera de decisi√≥n aprendida
- Permite comparaci√≥n visual directa

**¬øQu√© nos dice?**

- **Coincidencia visual**: Si las predicciones siguen patrones l√≥gicos
- **Errores obvios**: Casos donde el modelo claramente se equivoca
- **Consistencia**: Si la frontera de decisi√≥n es razonable

### Interpretaci√≥n de Resultados

#### ‚úÖ **Se√±ales de Predicciones Confiables:**

1. **Accuracy de validaci√≥n > 0.8**

   - El modelo funciona bien en datos conocidos
   - Alta probabilidad de funcionar en datos nuevos

2. **Casos extremos correctos**

   - Frutas obviamente maduras ‚Üí predicci√≥n "madura"
   - Frutas obviamente no maduras ‚Üí predicci√≥n "no madura"

3. **Alta confianza en predicciones**

   - Probabilidades cercanas a 0 o 1
   - Pocas predicciones inciertas

4. **Frontera de decisi√≥n l√≥gica**
   - Separaci√≥n clara entre clases
   - Sin patrones extra√±os o contradictorios

#### ‚ö†Ô∏è **Se√±ales de Problemas:**

1. **Accuracy de validaci√≥n < 0.6**

   - El modelo no generaliza bien
   - Necesita m√°s entrenamiento o datos

2. **Casos extremos incorrectos**

   - Frutas obvias clasificadas mal
   - Indica problemas fundamentales

3. **Baja confianza generalizada**

   - Muchas predicciones inciertas
   - Modelo no est√° seguro de sus decisiones

4. **Frontera de decisi√≥n extra√±a**
   - Patrones il√≥gicos o contradictorios
   - Posible sobreajuste o datos de mala calidad

### Recomendaciones para Uso en Producci√≥n

#### **Para Alta Confiabilidad:**

1. **Validar con dataset de prueba** antes de usar en producci√≥n
2. **Monitorear accuracy** en datos reales
3. **Revisar manualmente** casos de baja confianza
4. **Actualizar modelo** peri√≥dicamente con nuevos datos

#### **Para Casos Cr√≠ticos:**

1. **Usar umbral de confianza** m√°s estricto (>0.8 para aceptar predicci√≥n)
2. **Implementar revisi√≥n humana** para predicciones inciertas
3. **Mantener logs** de todas las predicciones
4. **Establecer alertas** para accuracy descendente

### Conclusi√≥n

**¬øC√≥mo saber si las predicciones son correctas?**

1. **Validar con datos conocidos** (accuracy > 0.8)
2. **Probar casos extremos** (comportamiento l√≥gico)
3. **Analizar confianza** (pocas predicciones inciertas)
4. **Visualizar resultados** (frontera de decisi√≥n l√≥gica)
5. **Monitorear continuamente** (validaci√≥n en producci√≥n)

**La clave**: No podemos estar 100% seguros, pero podemos estar **razonablemente confiados** bas√°ndonos en evidencia m√∫ltiple y validaci√≥n sistem√°tica.

---

## ¬øC√≥mo Verificar que el C√≥digo Funciona Correctamente?

### 1. **Indicadores de Ejecuci√≥n Exitosa**

**Durante la ejecuci√≥n, deber√≠as ver:**

```
============================================================
RED NEURONAL PARA CLASIFICACI√ìN DE FRUTAS MADURAS
============================================================
Cargando dataset de frutas...
Dataset cargado: 1000 muestras, 3 caracter√≠sticas
Dividiendo datos en entrenamiento (75%) y prueba (25%)...
Conjunto de entrenamiento: 750 muestras
Conjunto de prueba: 250 muestras
Creando red neuronal multicapa...
Arquitectura del modelo:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
capa_oculta (Dense)          (None, 10)                30
capa_salida (Dense)          (None, 1)                 11
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
Entrenando modelo...
Epoch 1/100
94/94 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000
...
Epoch X/100
94/94 [==============================] - 0s 3ms/step - loss: 0.XXXX - accuracy: 0.XXXX - val_loss: 0.XXXX - val_accuracy: 0.XXXX

Evaluando modelo...
Accuracy: 0.XXXX

Matriz de confusi√≥n:
[[XXX  XX]
 [ XX XXX]]

Reporte de clasificaci√≥n:
              precision    recall  f1-score   support

   No Madura       0.XX      0.XX      0.XX        XXX
       Madura       0.XX      0.XX      0.XX        XXX

    accuracy                           0.XX        XXX
   macro avg       0.XX      0.XX      0.XX        XXX
weighted avg       0.XX      0.XX      0.XX        XXX

Generando gr√°ficos...
[Se abren 4 ventanas con gr√°ficos]

============================================================
AN√ÅLISIS COMPLETADO
Accuracy final: 0.XXXX
============================================================
```

### 2. **M√©tricas de Calidad Esperadas**

**Accuracy esperado:**

- **> 0.85**: Excelente rendimiento
- **0.75 - 0.85**: Buen rendimiento
- **0.65 - 0.75**: Rendimiento aceptable
- **< 0.65**: Rendimiento pobre

**Matriz de confusi√≥n balanceada:**

```
[[Verdadero Negativo    Falso Positivo ]
 [Falso Negativo       Verdadero Positivo]]
```

**Caracter√≠sticas de un buen entrenamiento:**

- Accuracy de entrenamiento y validaci√≥n suben juntas
- No hay gap grande entre entrenamiento y validaci√≥n
- Early stopping detiene el entrenamiento autom√°ticamente
- Loss disminuye de manera estable

### 3. **Verificaci√≥n Visual**

**Gr√°fico de distribuci√≥n de clases:**

- Debe mostrar barras con n√∫meros similares para ambas clases
- Colores diferentes para "No Madura" y "Madura"

**Gr√°fico de frontera de decisi√≥n:**

- Regiones coloreadas que separan las clases
- Puntos de datos superpuestos con colores seg√∫n clase real
- Frontera suave y l√≥gica

**Historial de entrenamiento:**

- Curvas de accuracy y loss que mejoran con el tiempo
- Curvas de entrenamiento y validaci√≥n cercanas entre s√≠

### 4. **Se√±ales de Problemas**

**Si algo no funciona bien:**

‚ùå **Error de archivo no encontrado:**

```
FileNotFoundError: [Errno 2] No such file or directory: 'frutas_sinteticas_1000.csv'
```

**Soluci√≥n**: Verificar que el archivo CSV est√© en la misma carpeta

‚ùå **Accuracy muy bajo (< 0.6):**

- Posibles causas: Datos mal balanceados, modelo muy simple, datos de mala calidad
- **Soluci√≥n**: Revisar el dataset, aumentar la complejidad del modelo

‚ùå **Sobreajuste (accuracy entrenamiento >> accuracy validaci√≥n):**

- Posibles causas: Modelo muy complejo, pocos datos
- **Soluci√≥n**: Reducir complejidad, agregar regularizaci√≥n, m√°s datos

‚ùå **Subajuste (ambas accuracys bajas):**

- Posibles causas: Modelo muy simple, datos insuficientes
- **Soluci√≥n**: Aumentar complejidad del modelo, mejorar caracter√≠sticas

### 5. **Pruebas Adicionales**

**Para verificar que todo funciona:**

1. **Ejecutar m√∫ltiples veces:**

   ```bash
   python red_neuronal_frutas.py
   python red_neuronal_frutas.py
   python red_neuronal_frutas.py
   ```

   - Los resultados deben ser similares (random_state=42)

2. **Verificar archivos generados:**

   - El script debe ejecutarse sin errores
   - Los gr√°ficos deben abrirse autom√°ticamente
   - No debe haber mensajes de error en consola

3. **Probar con datos nuevos:**
   - Crear frutas sint√©ticas con valores extremos
   - Verificar que las predicciones sean razonables
   - La frontera de decisi√≥n debe ser l√≥gica

### 6. **Interpretaci√≥n de Resultados**

**Un modelo exitoso deber√≠a:**

- ‚úÖ Accuracy > 0.8 en datos de prueba
- ‚úÖ Matriz de confusi√≥n balanceada
- ‚úÖ Frontera de decisi√≥n l√≥gica y suave
- ‚úÖ Curvas de entrenamiento estables
- ‚úÖ Early stopping funcionando
- ‚úÖ Gr√°ficos gener√°ndose correctamente

**Si cumple estos criterios, el c√≥digo est√° funcionando correctamente y la red neuronal est√° aprendiendo efectivamente a clasificar frutas maduras de no maduras.**
